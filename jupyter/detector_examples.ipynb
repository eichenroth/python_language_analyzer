{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from python_language_analyzer.analyzer import Analyzer\n",
    "from python_language_analyzer.detectors.built_in_function_detector import BuiltInFunctionDetector\n",
    "from python_language_analyzer.detectors.class_detector import ClassDetector\n",
    "from python_language_analyzer.detectors.control_flow_detector import ControlFlowDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02597fecdb9403d9e885c23f8957854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Dropdown</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Dropdown(options=('./files/built_in_function.py', './files/control_flow.py', './files/hierarchical_softmax.py', './files/multiple_inheritances.py'), value='./files/built_in_function.py')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_names = ['./files/' + file for file in os.listdir('./files')]\n",
    "\n",
    "file_name_select = ipywidgets.Dropdown(options = file_names, value = file_names[0])\n",
    "file_name_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = file_name_select.value\n",
    "with open(file_name, 'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb84bc2030f4c5d94171bc99d564455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Dropdown</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Dropdown(options=(<class 'python_language_analyzer.detectors.class_detector.ClassDetector'>, <class 'python_language_analyzer.detectors.control_flow_detector.ControlFlowDetector'>, <class 'python_language_analyzer.detectors.built_in_function_detector.BuiltInFunctionDetector'>), value=<class 'python_language_analyzer.detectors.class_detector.ClassDetector'>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "detectors = [ClassDetector, ControlFlowDetector, BuiltInFunctionDetector]\n",
    "\n",
    "detector_select = ipywidgets.Dropdown(options = detectors, value = detectors[0])\n",
    "\n",
    "detector_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = Analyzer(file, [detector_select.value])\n",
    "detections = analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection name:  class\n",
      "detection lines:  14 61\n",
      "detection info: {'name': 'TreeParser', 'method_number': 6, 'nested': False}\n",
      "\n",
      "detection name:  class\n",
      "detection lines:  64 250\n",
      "detection info: {'name': 'BinaryHierarchicalSoftmaxFunction', 'method_number': 10, 'nested': False}\n",
      "\n",
      "detection name:  class\n",
      "detection lines:  253 364\n",
      "detection info: {'name': 'BinaryHierarchicalSoftmax', 'method_number': 5, 'nested': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for detection in detections:\n",
    "    print('detection name: ', detection.DETECTION_NAME)\n",
    "    print('detection lines: ', detection.begin, detection.end)\n",
    "    print('detection info:', detection.info)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\timport copy\n",
      "2\t\n",
      "3\timport numpy\n",
      "4\timport six\n",
      "5\t\n",
      "6\tfrom chainer.backends import cuda\n",
      "7\tfrom chainer import function\n",
      "8\tfrom chainer.initializers import uniform\n",
      "9\tfrom chainer import link\n",
      "10\tfrom chainer.utils import type_check\n",
      "11\tfrom chainer import variable\n",
      "12\t\n",
      "13\t\n",
      "14\tclass TreeParser(object):\n",
      "15\t\n",
      "16\t    def __init__(self):\n",
      "17\t        self.next_id = 0\n",
      "18\t\n",
      "19\t    def size(self):\n",
      "20\t        return self.next_id\n",
      "21\t\n",
      "22\t    def get_paths(self):\n",
      "23\t        return self.paths\n",
      "24\t\n",
      "25\t    def get_codes(self):\n",
      "26\t        return self.codes\n",
      "27\t\n",
      "28\t    def parse(self, tree):\n",
      "29\t        self.next_id = 0\n",
      "30\t        self.path = []\n",
      "31\t        self.code = []\n",
      "32\t        self.paths = {}\n",
      "33\t        self.codes = {}\n",
      "34\t        self._parse(tree)\n",
      "35\t\n",
      "36\t        assert(len(self.path) == 0)\n",
      "37\t        assert(len(self.code) == 0)\n",
      "38\t        assert(len(self.paths) == len(self.codes))\n",
      "39\t\n",
      "40\t    def _parse(self, node):\n",
      "41\t        if isinstance(node, tuple):\n",
      "42\t            # internal node\n",
      "43\t            if len(node) != 2:\n",
      "44\t                raise ValueError(\n",
      "45\t                    'All internal nodes must have two child nodes')\n",
      "46\t            left, right = node\n",
      "47\t            self.path.append(self.next_id)\n",
      "48\t            self.next_id += 1\n",
      "49\t            self.code.append(1.0)\n",
      "50\t            self._parse(left)\n",
      "51\t\n",
      "52\t            self.code[-1] = -1.0\n",
      "53\t            self._parse(right)\n",
      "54\t\n",
      "55\t            self.path.pop()\n",
      "56\t            self.code.pop()\n",
      "57\t\n",
      "58\t        else:\n",
      "59\t            # leaf node\n",
      "60\t            self.paths[node] = numpy.array(self.path, dtype=numpy.int32)\n",
      "61\t            self.codes[node] = numpy.array(self.code, dtype=numpy.float32)\n",
      "62\t\n",
      "63\t\n",
      "64\tclass BinaryHierarchicalSoftmaxFunction(function.Function):\n",
      "65\t\n",
      "66\t    \"\"\"Hierarchical softmax function based on a binary tree.\n",
      "67\t\n",
      "68\t    This function object should be allocated beforehand, and be copied on every\n",
      "69\t    forward computation, since the initializer parses the given tree. See the\n",
      "70\t    implementation of :class:`BinaryHierarchicalSoftmax` for details.\n",
      "71\t\n",
      "72\t    Args:\n",
      "73\t        tree: A binary tree made with tuples like ``((1, 2), 3)``.\n",
      "74\t\n",
      "75\t    .. seealso::\n",
      "76\t       See :class:`BinaryHierarchicalSoftmax` for details.\n",
      "77\t\n",
      "78\t    \"\"\"\n",
      "79\t\n",
      "80\t    def __init__(self, tree):\n",
      "81\t        parser = TreeParser()\n",
      "82\t        parser.parse(tree)\n",
      "83\t        paths = parser.get_paths()\n",
      "84\t        codes = parser.get_codes()\n",
      "85\t        n_vocab = max(paths.keys()) + 1\n",
      "86\t\n",
      "87\t        self.paths = numpy.concatenate(\n",
      "88\t            [paths[i] for i in range(n_vocab) if i in paths])\n",
      "89\t        self.codes = numpy.concatenate(\n",
      "90\t            [codes[i] for i in range(n_vocab) if i in codes])\n",
      "91\t        begins = numpy.empty((n_vocab + 1,), dtype=numpy.int32)\n",
      "92\t        begins[0] = 0\n",
      "93\t        for i in range(0, n_vocab):\n",
      "94\t            length = len(paths[i]) if i in paths else 0\n",
      "95\t            begins[i + 1] = begins[i] + length\n",
      "96\t        self.begins = begins\n",
      "97\t\n",
      "98\t        self.parser_size = parser.size()\n",
      "99\t\n",
      "100\t    def check_type_forward(self, in_types):\n",
      "101\t        type_check.expect(in_types.size() == 3)\n",
      "102\t        x_type, t_type, w_type = in_types\n",
      "103\t\n",
      "104\t        type_check.expect(\n",
      "105\t            x_type.dtype == numpy.float32,\n",
      "106\t            x_type.ndim == 2,\n",
      "107\t            t_type.dtype == numpy.int32,\n",
      "108\t            t_type.ndim == 1,\n",
      "109\t            x_type.shape[0] == t_type.shape[0],\n",
      "110\t            w_type.dtype == numpy.float32,\n",
      "111\t            w_type.ndim == 2,\n",
      "112\t            w_type.shape[0] == self.parser_size,\n",
      "113\t            w_type.shape[1] == x_type.shape[1],\n",
      "114\t        )\n",
      "115\t\n",
      "116\t    def to_gpu(self, device=None):\n",
      "117\t        with cuda._get_device(device):\n",
      "118\t            self.paths = cuda.to_gpu(self.paths)\n",
      "119\t            self.codes = cuda.to_gpu(self.codes)\n",
      "120\t            self.begins = cuda.to_gpu(self.begins)\n",
      "121\t\n",
      "122\t    def to_cpu(self):\n",
      "123\t        self.paths = cuda.to_cpu(self.paths)\n",
      "124\t        self.codes = cuda.to_cpu(self.codes)\n",
      "125\t        self.begins = cuda.to_cpu(self.begins)\n",
      "126\t\n",
      "127\t    def forward_cpu(self, inputs):\n",
      "128\t        x, t, W = inputs\n",
      "129\t\n",
      "130\t        loss = numpy.float32(0.0)\n",
      "131\t        for ix, it in six.moves.zip(x, t):\n",
      "132\t            loss += self._forward_cpu_one(ix, it, W)\n",
      "133\t        return numpy.array(loss),\n",
      "134\t\n",
      "135\t    def _forward_cpu_one(self, x, t, W):\n",
      "136\t        begin = self.begins[t]\n",
      "137\t        end = self.begins[t + 1]\n",
      "138\t\n",
      "139\t        w = W[self.paths[begin:end]]\n",
      "140\t        wxy = w.dot(x) * self.codes[begin:end]\n",
      "141\t        loss = numpy.logaddexp(0.0, -wxy)  # == log(1 + exp(-wxy))\n",
      "142\t        return numpy.sum(loss)\n",
      "143\t\n",
      "144\t    def backward_cpu(self, inputs, grad_outputs):\n",
      "145\t        x, t, W = inputs\n",
      "146\t        gloss, = grad_outputs\n",
      "147\t        gx = numpy.empty_like(x)\n",
      "148\t        gW = numpy.zeros_like(W)\n",
      "149\t        for i, (ix, it) in enumerate(six.moves.zip(x, t)):\n",
      "150\t            gx[i] = self._backward_cpu_one(ix, it, W, gloss, gW)\n",
      "151\t        return gx, None, gW\n",
      "152\t\n",
      "153\t    def _backward_cpu_one(self, x, t, W, gloss, gW):\n",
      "154\t        begin = self.begins[t]\n",
      "155\t        end = self.begins[t + 1]\n",
      "156\t\n",
      "157\t        path = self.paths[begin:end]\n",
      "158\t        w = W[path]\n",
      "159\t        wxy = w.dot(x) * self.codes[begin:end]\n",
      "160\t        g = -gloss * self.codes[begin:end] / (1.0 + numpy.exp(wxy))\n",
      "161\t        gx = g.dot(w)\n",
      "162\t        gw = g.reshape((g.shape[0], 1)).dot(x.reshape(1, x.shape[0]))\n",
      "163\t        gW[path] += gw\n",
      "164\t        return gx\n",
      "165\t\n",
      "166\t    def forward_gpu(self, inputs):\n",
      "167\t        x, t, W = inputs\n",
      "168\t        max_length = cuda.reduce(\n",
      "169\t            'T t, raw T begins', 'T out', 'begins[t + 1] - begins[t]',\n",
      "170\t            'max(a, b)', 'out = a', '0',\n",
      "171\t            'binary_hierarchical_softmax_max_length')(t, self.begins)\n",
      "172\t        max_length = cuda.to_cpu(max_length)[()]\n",
      "173\t\n",
      "174\t        length = max_length * x.shape[0]\n",
      "175\t        ls = cuda.cupy.empty((length,), dtype=numpy.float32)\n",
      "176\t        n_in = x.shape[1]\n",
      "177\t        wxy = cuda.cupy.empty_like(ls)\n",
      "178\t        cuda.elementwise(\n",
      "179\t            '''raw T x, raw T w, raw int32 ts, raw int32 paths,\n",
      "180\t            raw T codes, raw int32 begins, int32 c, int32 max_length''',\n",
      "181\t            'T ls, T wxy',\n",
      "182\t            '''\n",
      "183\t            int ind = i / max_length;\n",
      "184\t            int offset = i - ind * max_length;\n",
      "185\t            int t = ts[ind];\n",
      "186\t\n",
      "187\t            int begin = begins[t];\n",
      "188\t            int length = begins[t + 1] - begins[t];\n",
      "189\t\n",
      "190\t            if (offset < length) {\n",
      "191\t              int p = begin + offset;\n",
      "192\t              int node = paths[p];\n",
      "193\t\n",
      "194\t              T wx = 0;\n",
      "195\t              for (int j = 0; j < c; ++j) {\n",
      "196\t                int w_ind[] = {node, j};\n",
      "197\t                int x_ind[] = {ind, j};\n",
      "198\t                wx += w[w_ind] * x[x_ind];\n",
      "199\t              }\n",
      "200\t              wxy = wx * codes[p];\n",
      "201\t              ls = log(1 + exp(-wxy));\n",
      "202\t            } else {\n",
      "203\t              ls = 0;\n",
      "204\t            }\n",
      "205\t            ''',\n",
      "206\t            'binary_hierarchical_softmax_forward'\n",
      "207\t        )(x, W, t, self.paths, self.codes, self.begins, n_in, max_length, ls,\n",
      "208\t          wxy)\n",
      "209\t        self.max_length = max_length\n",
      "210\t        self.wxy = wxy\n",
      "211\t        return ls.sum(),\n",
      "212\t\n",
      "213\t    def backward_gpu(self, inputs, grad_outputs):\n",
      "214\t        x, t, W = inputs\n",
      "215\t        gloss, = grad_outputs\n",
      "216\t\n",
      "217\t        n_in = x.shape[1]\n",
      "218\t        gx = cuda.cupy.zeros_like(x)\n",
      "219\t        gW = cuda.cupy.zeros_like(W)\n",
      "220\t        cuda.elementwise(\n",
      "221\t            '''T wxy, raw T x, raw T w, raw int32 ts, raw int32 paths,\n",
      "222\t            raw T codes, raw int32 begins, raw T gloss,\n",
      "223\t            int32 c, int32 max_length''',\n",
      "224\t            'raw T gx, raw T gw',\n",
      "225\t            '''\n",
      "226\t            int ind = i / max_length;\n",
      "227\t            int offset = i - ind * max_length;\n",
      "228\t            int t = ts[ind];\n",
      "229\t\n",
      "230\t            int begin = begins[t];\n",
      "231\t            int length = begins[t + 1] - begins[t];\n",
      "232\t\n",
      "233\t            if (offset < length) {\n",
      "234\t              int p = begin + offset;\n",
      "235\t              int node = paths[p];\n",
      "236\t              T code = codes[p];\n",
      "237\t\n",
      "238\t              T g = -gloss[0] * code / (1.0 + exp(wxy));\n",
      "239\t              for (int j = 0; j < c; ++j) {\n",
      "240\t                int w_ind[] = {node, j};\n",
      "241\t                int x_ind[] = {ind, j};\n",
      "242\t                atomicAdd(&gx[x_ind], g * w[w_ind]);\n",
      "243\t                atomicAdd(&gw[w_ind], g * x[x_ind]);\n",
      "244\t              }\n",
      "245\t            }\n",
      "246\t            ''',\n",
      "247\t            'binary_hierarchical_softmax_bwd'\n",
      "248\t        )(self.wxy, x, W, t, self.paths, self.codes, self.begins, gloss, n_in,\n",
      "249\t          self.max_length, gx, gW)\n",
      "250\t        return gx, None, gW\n",
      "251\t\n",
      "252\t\n",
      "253\tclass BinaryHierarchicalSoftmax(link.Link):\n",
      "254\t\n",
      "255\t    \"\"\"Hierarchical softmax layer over binary tree.\n",
      "256\t\n",
      "257\t    In natural language applications, vocabulary size is too large to use\n",
      "258\t    softmax loss.\n",
      "259\t    Instead, the hierarchical softmax uses product of sigmoid functions.\n",
      "260\t    It costs only :math:`O(\\\\log(n))` time where :math:`n` is the vocabulary\n",
      "261\t    size in average.\n",
      "262\t\n",
      "263\t    At first a user need to prepare a binary tree whose each leaf is\n",
      "264\t    corresponding to a word in a vocabulary.\n",
      "265\t    When a word :math:`x` is given, exactly one path from the root of the tree\n",
      "266\t    to the leaf of the word exists.\n",
      "267\t    Let :math:`\\\\mbox{path}(x) = ((e_1, b_1), \\\\dots, (e_m, b_m))` be the path\n",
      "268\t    of :math:`x`, where :math:`e_i` is an index of :math:`i`-th internal node,\n",
      "269\t    and :math:`b_i \\\\in \\\\{-1, 1\\\\}` indicates direction to move at\n",
      "270\t    :math:`i`-th internal node (-1 is left, and 1 is right).\n",
      "271\t    Then, the probability of :math:`x` is given as below:\n",
      "272\t\n",
      "273\t    .. math::\n",
      "274\t\n",
      "275\t       P(x) &= \\\\prod_{(e_i, b_i) \\\\in \\\\mbox{path}(x)}P(b_i | e_i)  \\\\\\\\\n",
      "276\t            &= \\\\prod_{(e_i, b_i) \\\\in \\\\mbox{path}(x)}\\\\sigma(b_i x^\\\\top\n",
      "277\t               w_{e_i}),\n",
      "278\t\n",
      "279\t    where :math:`\\\\sigma(\\\\cdot)` is a sigmoid function, and :math:`w` is a\n",
      "280\t    weight matrix.\n",
      "281\t\n",
      "282\t    This function costs :math:`O(\\\\log(n))` time as an average length of paths\n",
      "283\t    is :math:`O(\\\\log(n))`, and :math:`O(n)` memory as the number of internal\n",
      "284\t    nodes equals :math:`n - 1`.\n",
      "285\t\n",
      "286\t    Args:\n",
      "287\t        in_size (int): Dimension of input vectors.\n",
      "288\t        tree: A binary tree made with tuples like `((1, 2), 3)`.\n",
      "289\t\n",
      "290\t    Attributes:\n",
      "291\t        W (~chainer.Variable): Weight parameter matrix.\n",
      "292\t\n",
      "293\t    See: Hierarchical Probabilistic Neural Network Language Model [Morin+,\n",
      "294\t    AISTAT2005].\n",
      "295\t\n",
      "296\t    \"\"\"\n",
      "297\t\n",
      "298\t    def __init__(self, in_size, tree):\n",
      "299\t        # This function object is copied on every forward computation.\n",
      "300\t        super(BinaryHierarchicalSoftmax, self).__init__()\n",
      "301\t        self._func = BinaryHierarchicalSoftmaxFunction(tree)\n",
      "302\t\n",
      "303\t        with self.init_scope():\n",
      "304\t            self.W = variable.Parameter(uniform.Uniform(1),\n",
      "305\t                                        (self._func.parser_size, in_size))\n",
      "306\t\n",
      "307\t    def to_gpu(self, device=None):\n",
      "308\t        with cuda._get_device(device):\n",
      "309\t            super(BinaryHierarchicalSoftmax, self).to_gpu(device)\n",
      "310\t            self._func.to_gpu(device)\n",
      "311\t\n",
      "312\t    def to_cpu(self):\n",
      "313\t        super(BinaryHierarchicalSoftmax, self).to_cpu()\n",
      "314\t        self._func.to_cpu()\n",
      "315\t\n",
      "316\t    @staticmethod\n",
      "317\t    def create_huffman_tree(word_counts):\n",
      "318\t        \"\"\"Makes a Huffman tree from a dictionary containing word counts.\n",
      "319\t\n",
      "320\t        This method creates a binary Huffman tree, that is required for\n",
      "321\t        :class:`BinaryHierarchicalSoftmax`.\n",
      "322\t        For example, ``{0: 8, 1: 5, 2: 6, 3: 4}`` is converted to\n",
      "323\t        ``((3, 1), (2, 0))``.\n",
      "324\t\n",
      "325\t        Args:\n",
      "326\t            word_counts (dict of int key and int or float values):\n",
      "327\t                Dictionary representing counts of words.\n",
      "328\t\n",
      "329\t        Returns:\n",
      "330\t            Binary Huffman tree with tuples and keys of ``word_coutns``.\n",
      "331\t\n",
      "332\t        \"\"\"\n",
      "333\t        if len(word_counts) == 0:\n",
      "334\t            raise ValueError('Empty vocabulary')\n",
      "335\t\n",
      "336\t        q = six.moves.queue.PriorityQueue()\n",
      "337\t        # Add unique id to each entry so that we can compare two entries with\n",
      "338\t        # same counts.\n",
      "339\t        # Note that itreitems randomly order the entries.\n",
      "340\t        for uid, (w, c) in enumerate(six.iteritems(word_counts)):\n",
      "341\t            q.put((c, uid, w))\n",
      "342\t\n",
      "343\t        while q.qsize() >= 2:\n",
      "344\t            (count1, id1, word1) = q.get()\n",
      "345\t            (count2, id2, word2) = q.get()\n",
      "346\t            count = count1 + count2\n",
      "347\t            tree = (word1, word2)\n",
      "348\t            q.put((count, min(id1, id2), tree))\n",
      "349\t\n",
      "350\t        return q.get()[2]\n",
      "351\t\n",
      "352\t    def __call__(self, x, t):\n",
      "353\t        \"\"\"Computes the loss value for given input and ground truth labels.\n",
      "354\t\n",
      "355\t        Args:\n",
      "356\t            x (~chainer.Variable): Input to the classifier at each node.\n",
      "357\t            t (~chainer.Variable): Batch of ground truth labels.\n",
      "358\t\n",
      "359\t        Returns:\n",
      "360\t            ~chainer.Variable: Loss value.\n",
      "361\t\n",
      "362\t        \"\"\"\n",
      "363\t        f = copy.copy(self._func)  # creates a copy of the function node\n",
      "364\t        return f(x, t, self.W)\n",
      "365\t\n",
      "366\t\n",
      "367\t\n",
      "368\t\n",
      "369\t\n",
      "370\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(''.join([str(i + 1) + '\\t' + line for i, line in enumerate(file)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
